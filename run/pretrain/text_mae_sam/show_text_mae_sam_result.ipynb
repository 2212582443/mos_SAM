{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/projects/src/github.com/any35/MOS\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "os.chdir(\"../../..\")\n",
    "print(os.path.abspath(\"./\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SamModel' from 'run.pretrain.cls_mmae_sam.model' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/data/projects/src/github.com/any35/MOS/run/pretrain/text_mae_sam/show_text_mae_sam_result.ipynb 单元格 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blib-ubuntu/data/projects/src/github.com/any35/MOS/run/pretrain/text_mae_sam/show_text_mae_sam_result.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrun\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpretrain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcls_mmae_sam\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbatch_soft_dice\u001b[39;00m \u001b[39mimport\u001b[39;00m DiceScore\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blib-ubuntu/data/projects/src/github.com/any35/MOS/run/pretrain/text_mae_sam/show_text_mae_sam_result.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrun\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpretrain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcls_mmae_sam\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msam_model_simple\u001b[39;00m \u001b[39mimport\u001b[39;00m SamModelSimple\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blib-ubuntu/data/projects/src/github.com/any35/MOS/run/pretrain/text_mae_sam/show_text_mae_sam_result.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrun\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpretrain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext_mae_sam\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_factory\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelFactory\n",
      "File \u001b[0;32m/data/projects/src/github.com/any35/MOS/run/pretrain/cls_mmae_sam/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdataclasses\u001b[39;00m \u001b[39mimport\u001b[39;00m dataclass, field\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m List\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     SamModel,\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     HfArgumentParser,\n\u001b[1;32m      8\u001b[0m     TrainingArguments,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39membedding\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     12\u001b[0m     DenseEmbeddingsTensor,\n\u001b[1;32m     13\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'SamModel' from 'run.pretrain.cls_mmae_sam.model' (unknown location)"
     ]
    }
   ],
   "source": [
    "from run.pretrain.cls_mmae_sam.batch_soft_dice import DiceScore\n",
    "from run.pretrain.cls_mmae_sam.model.sam_model_simple import SamModelSimple\n",
    "from run.pretrain.text_mae_sam.model_factory import ModelFactory\n",
    "from run.pretrain.text_mae_sam.sam_dataset_compat_simple import SAMDatasetCompatSimple\n",
    "import torch\n",
    "from torch import Tensor,autocast\n",
    "\n",
    "device = \"cuda:0\"\n",
    "run_name = 'text_mae_sam_simple2-reprod-0'\n",
    "output_dir = f\".checkpoint/{run_name}\"\n",
    "dataset = 'reprod'\n",
    "valid_dataset_id = 0\n",
    "eval_batch_size = 149\n",
    "\n",
    "model_factory = ModelFactory(device, run_name)\n",
    "model: SamModelSimple = model_factory.load_model(f\"{output_dir}/latest\")\n",
    "\n",
    "new_dataset = SAMDatasetCompatSimple(\n",
    "            base_path=f\".cache/dataset/text-mae-sam-dataset/dataset-{dataset}-{valid_dataset_id}.pt\",\n",
    "            device=device,\n",
    "            only_cmri_dataset=True,\n",
    "        )\n",
    "model.eval()\n",
    "\n",
    "print(\"evaluating...\")\n",
    "dice_losses = []\n",
    "avg_hausdorff_dist_losses = []\n",
    "max_hausdorff_dist_losses = []\n",
    "model.eval()\n",
    "KEEP_WORST_COUNT = 30\n",
    "last_image_list: list[tuple[Tensor, Tensor, Tensor]] = []\n",
    "last_dice_list = []\n",
    "\n",
    "calc_dice_score = DiceScore()\n",
    "\n",
    "with torch.no_grad(), autocast(enabled=True):\n",
    "    for batch in new_dataset.shuffer_valid_id(eval_batch_size):\n",
    "        image, labeled_segment, token = new_dataset.batch_get_valid(batch)\n",
    "\n",
    "        pred_masks = model.forward_image(image, token)\n",
    "\n",
    "        # (bs, h, w)\n",
    "        first_pred_masks = pred_masks[:, 0, 0, :, :]\n",
    "\n",
    "        dice_loss = calc_dice_score(first_pred_masks, labeled_segment, reduce=False).tolist()\n",
    "        dice_losses.extend(dice_loss)\n",
    "\n",
    "        # 求最差的KEEP_WORST_COUNT个\n",
    "        dice_loss = [(i, loss) for i, loss in enumerate(dice_loss)]\n",
    "        dice_loss.sort(key=lambda x: x[1])\n",
    "        dice_loss_index = [i for i, _ in dice_loss[:KEEP_WORST_COUNT]]\n",
    "        last_image_list.append(\n",
    "            (\n",
    "                image[dice_loss_index],\n",
    "                labeled_segment[dice_loss_index],\n",
    "                first_pred_masks[dice_loss_index],\n",
    "            )\n",
    "        )\n",
    "        dice_list = [score for _, score in dice_loss[:KEEP_WORST_COUNT]]\n",
    "        last_dice_list.extend(dice_list)\n",
    "\n",
    "        if len(last_image_list) > 1:  # 列表只保留最差的KEEP_WORST_COUNT个\n",
    "            last_image_list = torch.cat(last_image_list, dim=0)\n",
    "            last_dice_list = [(i, loss) for i, loss in enumerate(last_dice_list)]\n",
    "            last_dice_list.sort(key=lambda x: x[1])\n",
    "            dice_loss_index = [i for i, _ in last_dice_list[:KEEP_WORST_COUNT]]\n",
    "            last_dice_list = [score for _, score in last_dice_list[:KEEP_WORST_COUNT]]\n",
    "            last_image_list = [\n",
    "                (\n",
    "                    image[dice_loss_index],\n",
    "                    labeled_segment[dice_loss_index],\n",
    "                    first_pred_masks[dice_loss_index],\n",
    "                )\n",
    "            ]\n",
    "\n",
    "# 只选dice取最差的KEEP_WORST_COUNT个\n",
    "image, labeled_segment, first_pred_masks = last_image_list[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
