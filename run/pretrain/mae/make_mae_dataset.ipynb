{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "os.chdir(\"../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data2/huping/home/projects/src/github.com/any35/MOS\n"
     ]
    }
   ],
   "source": [
    "print(os.path.abspath(\"./\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed .cache/dataset/mmae-dataset/split-1.5mm/ACDC.pt...\t 38346 images\n",
      "processed .cache/dataset/mmae-dataset/split-1.5mm/CMRI-private.pt...\t 48195 images\n",
      "processed .cache/dataset/mmae-dataset/split-1.5mm/CT_MR_2D_Dataset_DA.pt...\t 1568 images\n",
      "processed .cache/dataset/mmae-dataset/split-1.5mm/CoA_MRIData.pt...\t 2641 images\n",
      "processed .cache/dataset/mmae-dataset/split-1.5mm/DOI_10.7910_DVN_CI3WB6.pt...\t 42225 images\n",
      "processed .cache/dataset/mmae-dataset/split-1.5mm/DOI_10.7910_DVN_JMZHVI.pt...\t 16000 images\n",
      "processed .cache/dataset/mmae-dataset/split-1.5mm/DOI_10.7910_DVN_N1R1Q4.pt...\t 1050 images\n",
      "processed .cache/dataset/mmae-dataset/split-1.5mm/EMIDEC.pt...\t 1066 images\n",
      "processed .cache/dataset/mmae-dataset/split-1.5mm/HVSMR2016.pt...\t 3600 images\n",
      "processed .cache/dataset/mmae-dataset/split-1.5mm/LeftAtrialSegmentationChallenge2013.pt...\t 3568 images\n",
      "processed .cache/dataset/mmae-dataset/split-1.5mm/LeftAtrialSegmentationKaggle.pt...\t 2271 images\n",
      "processed .cache/dataset/mmae-dataset/split-1.5mm/MMWHS2017.pt...\t 23980 images\n",
      "processed .cache/dataset/mmae-dataset/split-1.5mm/MyoPS2020.pt...\t 522 images\n",
      "processed .cache/dataset/mmae-dataset/split-1.5mm/RegionalMulti-viewLearningForCardiacMotionAnalysis.pt...\t 4101 images\n",
      "processed .cache/dataset/mmae-dataset/split-1.5mm/SunnybrookCardiacData.pt...\t 51545 images\n",
      "valid images: .cache/dataset/mmae-dataset/split-1.5mm/VarDA.pt\n",
      "processed .cache/dataset/mmae-dataset/split-1.5mm/VarDA.pt...\t 1077 images\n",
      "processed .cache/dataset/mmae-dataset/split-1.5mm/mnms.pt...\t 106159 images\n",
      "processed .cache/dataset/mmae-dataset/split-1.5mm/msd-seg.pt...\t 3568 images\n",
      "processed .cache/dataset/mmae-dataset/split-1.5mm/yorku_CardiacMRIDataset.pt...\t 7980 images\n",
      "total 358385 train images, 1077 valid images!\n"
     ]
    }
   ],
   "source": [
    "# make mae dataset, (只保留图像信息, 不要mask)\n",
    "import torch, glob, os\n",
    "\n",
    "os.makedirs(\".cache/dataset/mae-dataset/\", exist_ok=True)\n",
    "\n",
    "valid_set = set([\"VarDA.pt\"])\n",
    "\n",
    "ignore_set = set([\"CMRI.pt\"])\n",
    "\n",
    "train_all_images = []\n",
    "valid_all_images = []\n",
    "cmri_train_images_index = [[] for _ in range(10)]\n",
    "cmri_valid_images_index = [[] for _ in range(10)]\n",
    "\n",
    "src_dir = \".cache/dataset/mmae-dataset/split-1.5mm\"\n",
    "\n",
    "file_list = glob.glob(f\"{src_dir}/*.pt\")\n",
    "file_list.sort()\n",
    "\n",
    "for file in file_list:\n",
    "    file_name = file.split(\"/\")[-1]\n",
    "    if file_name in ignore_set:\n",
    "        continue\n",
    "\n",
    "    is_valid_set = file_name in valid_set\n",
    "\n",
    "    data = torch.load(file)\n",
    "    image, meta = data[\"image\"], data[\"image_meta\"]\n",
    "    assert len(image.shape) == 3, f\"{image.shape}, {file}\"  # bs, h ,w\n",
    "    index_list = []\n",
    "    for i, image_type in enumerate(meta[:, 1].tolist()):\n",
    "        if image_type < 10:  # 0~9为各类图像\n",
    "            index_list.append(i)\n",
    "    image = image[index_list]\n",
    "\n",
    "    if is_valid_set:\n",
    "        print(\"valid images:\", file)\n",
    "        valid_all_images.append(image)\n",
    "    else:\n",
    "        train_all_images.append(image)\n",
    "\n",
    "    print(f\"processed {file}...\\t {image.shape[0]} images\")\n",
    "\n",
    "# cmri images\n",
    "data: dict[str, torch.Tensor] = torch.load(f\"{src_dir}/CMRI.pt\")\n",
    "# (bs, h, w), (bs, [uid, type])\n",
    "cmri_image_list, meta_list = data[\"image\"], data[\"image_meta\"]\n",
    "\n",
    "index_list = []\n",
    "for i, meta in enumerate(meta_list.tolist()):\n",
    "    uid, image_type = meta\n",
    "    if image_type >= 10 or image_type < 0:  # 0~9为各类图像\n",
    "        continue\n",
    "\n",
    "    partition = uid % 10\n",
    "\n",
    "    for s in range(10):\n",
    "        if s == partition:\n",
    "            cmri_valid_images_index[s].append(len(index_list))\n",
    "        else:\n",
    "            cmri_train_images_index[s].append(len(index_list))\n",
    "\n",
    "    index_list.append(i)\n",
    "\n",
    "cmri_image_list = cmri_image_list[index_list]\n",
    "\n",
    "train_all_images = torch.cat(train_all_images, dim=0).to(torch.uint8)\n",
    "valid_all_images = torch.cat(valid_all_images, dim=0).to(torch.uint8)\n",
    "\n",
    "cmri_train_images_index = [torch.tensor(t) for t in cmri_train_images_index]\n",
    "cmri_valid_images_index = [torch.tensor(t) for t in cmri_valid_images_index]\n",
    "\n",
    "data = {\n",
    "    \"image\": train_all_images,  # 训练集的图像\n",
    "    \"cmri_image\": cmri_image_list,  # cmri的全部图像(微调的时候用)\n",
    "}\n",
    "for i in range(10):\n",
    "    data[f\"cmri_image_index/{i}\"] = cmri_train_images_index[i]  # cmri微调的时候选择的图像id, for 10 folds valid\n",
    "torch.save(data, \".cache/dataset/mae-dataset/dataset-train.pt\")\n",
    "\n",
    "data = {\n",
    "    \"image\": valid_all_images,\n",
    "    \"cmri_image\": cmri_image_list,\n",
    "}\n",
    "for i in range(10):\n",
    "    data[f\"cmri_image_index/{i}\"] = cmri_valid_images_index[i]  # cmri微调的时候选择的验证图像, for 10 folds valid\n",
    "\n",
    "torch.save(data, \".cache/dataset/mae-dataset/dataset-valid.pt\")\n",
    "\n",
    "\n",
    "print(f\"total {train_all_images.shape[0]} train images, {valid_all_images.shape[0]} valid images!\")\n",
    "del train_all_images, valid_all_images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
