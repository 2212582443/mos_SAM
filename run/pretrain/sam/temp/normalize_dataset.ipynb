{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把所有的图片和分割大小调整到224*224\n",
    "import os, json\n",
    "from typing import Any\n",
    "\n",
    "datasets = [\n",
    "    \"~/dataset/cmri\",\n",
    "    \"~/dataset/acdc\",\n",
    "    \"~/dataset/mnms\",\n",
    "]\n",
    "datasets = [os.path.expanduser(dataset) for dataset in datasets]\n",
    "\n",
    "TARGET_SIZE = 224\n",
    "\n",
    "for dataset in datasets:\n",
    "    # 处理dataset.json\n",
    "    dataset_json = os.path.join(dataset, \"dataset.json\")\n",
    "    if not os.path.exists(f\"{dataset_json}.bak\"):\n",
    "        os.system(f\"cp {dataset_json} {dataset_json}.bak\")\n",
    "\n",
    "    with open(dataset_json, \"r\") as f:\n",
    "        dataset_dict = json.load(f)\n",
    "        subjects: list = dataset_dict[\"subjects\"]\n",
    "        for subject in subjects:\n",
    "            d, h, w = subject[\"shape\"]\n",
    "            scale = TARGET_SIZE / min(h, w)\n",
    "            h, w = int(h * scale), int(w * scale)\n",
    "            subject[\"shape\"] = [d, h, w]\n",
    "\n",
    "            sx, sy, sz = subject[\"spacing\"]\n",
    "            sx, sy = sx / scale, sy / scale\n",
    "            subject[\"spacing\"] = [sx, sy, sz]\n",
    "        files: list = dataset_dict[\"files\"]\n",
    "        for file in files:\n",
    "            d, h, w = file[\"shape\"]\n",
    "            scale = TARGET_SIZE / min(h, w)\n",
    "            h, w = int(h * scale), int(w * scale)\n",
    "            file[\"shape\"] = [d, h, w]\n",
    "\n",
    "            if file[\"segment_box_3d\"] is not None:\n",
    "                x1, y1, z1, x2, y2, z2 = file[\"segment_box_3d\"]\n",
    "                x1, y1, x2, y2 = int(x1 * scale), int(y1 * scale), int(x2 * scale), int(y2 * scale)\n",
    "                file[\"segment_box_3d\"] = [x1, y1, z1, x2, y2, z2]\n",
    "\n",
    "            segment_box_2d: dict[str, Any] = file[\"segment_box_2d\"]\n",
    "            segment_box_2d = {\n",
    "                k: [int(v[0] * scale), int(v[1] * scale), int(v[2] * scale), int(v[3] * scale)]\n",
    "                for k, v in segment_box_2d.items()\n",
    "            }\n",
    "\n",
    "            sx, sy, sz = file[\"spacing\"]\n",
    "            sx, sy = sx / scale, sy / scale\n",
    "            file[\"spacing\"] = [sx, sy, sz]\n",
    "\n",
    "    with open(dataset_json, \"w\") as f:\n",
    "        json.dump(dataset_dict, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "_image_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(\n",
    "            (TARGET_SIZE, TARGET_SIZE), antialias=True, interpolation=transforms.InterpolationMode.BILINEAR\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "_segment_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(\n",
    "            (TARGET_SIZE, TARGET_SIZE), antialias=True, interpolation=transforms.InterpolationMode.NEAREST\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "for dataset in datasets:\n",
    "    # list all npz files in dataset\n",
    "    npz_files = []\n",
    "    for root, dirs, files in os.walk(dataset):\n",
    "        for file in files:\n",
    "            if file.endswith(\".npz\"):\n",
    "                npz_files.append((root, file))\n",
    "\n",
    "    for root, file in npz_files:\n",
    "        full_path = os.path.join(root, file)\n",
    "        print(\"process file:\", full_path)\n",
    "        data = dict(np.load(full_path))\n",
    "        image = data[\"image\"]\n",
    "        image = torch.from_numpy(image)\n",
    "        image = _image_transform(image)\n",
    "        data[\"image\"] = image.numpy()\n",
    "        if \"segment\" in data:\n",
    "            segmentation = data[\"segment\"]\n",
    "            segmentation = torch.from_numpy(segmentation)\n",
    "            segmentation = _segment_transform(segmentation)\n",
    "            segmentation = segmentation.to(torch.uint8)\n",
    "            data[\"segment\"] = segmentation.numpy()\n",
    "            print(\"segmentation shape:\", segmentation.shape)\n",
    "        np.savez_compressed(full_path, **data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
